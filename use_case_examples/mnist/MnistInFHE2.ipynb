{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch = 2.0.1+cu117\n",
      "brevitas = 0.8.0\n",
      "concrete-ml = 1.1.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import brevitas\n",
    "import brevitas.nn as qnn\n",
    "\n",
    "from concrete.ml.torch.compile import compile_brevitas_qat_model\n",
    "\n",
    "print(f\"torch = {torch.__version__}\")\n",
    "print(f\"brevitas = {brevitas.__version__}\")\n",
    "print(f\"concrete-ml = {concrete.ml.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manage_dataset(train_kwargs, test_kwargs):\n",
    "    \"\"\"Get training and test parts of MNIST data-set.\"\"\"\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,)),\n",
    "            transforms.Lambda(torch.flatten),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Manage data-sets\n",
    "    dataset1 = datasets.MNIST(\"./data\", train=True, download=True, transform=transform)\n",
    "    dataset2 = datasets.MNIST(\"./data\", train=False, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efc7304ce20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loader, test_loader = manage_dataset({\"batch_size\": 32}, \n",
    "                                           {\"batch_size\": 32})\n",
    "img = test_loader.dataset.data[0]\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "               Lambda()\n",
       "           )"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = train_loader.dataset.data[0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "sparsity = 4  # smaller value => less active neurons\n",
    "quantization_bits = 6  # faster = more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import MNISTQATModel\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model = MNISTQATModel(quantization_bits, quantization_bits)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Load pre-trained model for post-training quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys = odict_keys(['fc1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'fc2.weight', 'bn2.weight', 'bn2.bias', 'bn2.running_mean', 'bn2.running_var', 'bn2.num_batches_tracked', 'fc3.weight', 'bn3.weight', 'bn3.bias', 'bn3.running_mean', 'bn3.running_var', 'bn3.num_batches_tracked', 'fc4.weight'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., 0.0000e+00, -0.0000e+00,\n",
       "                       3.6892e-41],\n",
       "                      [-0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "                       0.0000e+00],\n",
       "                      [2.7555e-41, 0.0000e+00, -0.0000e+00,  ..., -0.0000e+00, -0.0000e+00,\n",
       "                       0.0000e+00],\n",
       "                      ...,\n",
       "                      [-0.0000e+00, -0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "                       0.0000e+00],\n",
       "                      [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., -0.0000e+00, 0.0000e+00,\n",
       "                       -0.0000e+00],\n",
       "                      [-0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., -0.0000e+00, 0.0000e+00,\n",
       "                       0.0000e+00]])),\n",
       "             ('bn1.weight',\n",
       "              tensor([0.7123, 0.7720, 0.9259, 0.9730, 1.0520, 1.3993, 0.5174, 1.0830, 1.5790,\n",
       "                      1.6062, 0.7404, 1.4128, 1.1031, 1.2947, 0.2222, 0.8742, 1.6880, 1.1362,\n",
       "                      0.7398, 0.5878, 1.2915, 1.4451, 1.0649, 1.0399, 1.0684, 1.5972, 0.8065,\n",
       "                      0.9352, 0.7121, 1.4649, 1.1075, 1.4087, 1.1938, 1.3169, 1.3835, 1.1424,\n",
       "                      1.3313, 1.0537, 1.2013, 1.4401, 1.5001, 0.9287, 0.9505, 1.1382, 1.0056,\n",
       "                      0.7703, 0.7560, 1.1133, 1.3106, 0.5344, 1.0895, 1.7363, 1.0234, 0.6776,\n",
       "                      0.8975, 1.2915, 1.1069, 0.8033, 0.9164, 0.9745, 1.2590, 0.7175, 0.9694,\n",
       "                      1.3497, 1.4082, 0.7570, 0.9767, 1.1813, 1.1499, 1.0091, 0.9651, 0.9680,\n",
       "                      0.5967, 1.4861, 1.0773, 1.2327, 0.9494, 1.1650, 1.0987, 1.3717, 1.8518,\n",
       "                      1.1549, 1.3740, 0.8419, 1.3122, 1.2635, 1.1934, 0.9457, 1.6365, 0.4769,\n",
       "                      1.1690, 1.7826, 0.8416, 1.1649, 0.9725, 1.2670, 1.5868, 0.7062, 0.9584,\n",
       "                      1.6702, 1.3776, 0.9996, 0.5546, 1.1669, 1.1521, 0.5551, 0.1114, 1.4956,\n",
       "                      1.0328, 0.7900, 1.2516, 1.3846, 0.6764, 1.5339, 0.9481, 1.0375, 0.7193,\n",
       "                      0.6735, 1.0897, 1.1698, 1.0944, 0.7419, 0.2572, 0.8625, 0.9869, 1.0554,\n",
       "                      0.0158, 1.1793, 0.8559, 0.8365, 1.8671, 0.9099, 1.0783, 1.6054, 0.6438,\n",
       "                      0.9510, 1.3820, 1.1889, 1.7874, 1.0643, 0.8484, 1.2686, 1.5910, 1.1487,\n",
       "                      0.5294, 1.1675, 1.0573, 1.1630, 1.2999, 1.1726, 1.1373, 1.0745, 0.5521,\n",
       "                      0.9337, 1.1181, 1.2583, 1.2116, 0.7470, 0.8599, 1.3375, 0.8517, 1.4509,\n",
       "                      1.1624, 1.3725, 1.0765, 1.5319, 1.3806, 1.4296, 1.8672, 1.3410, 1.4857,\n",
       "                      1.2810, 1.3191, 0.5774, 0.8345, 0.2816, 0.9516, 1.1886, 0.6688, 0.9566,\n",
       "                      0.9948, 0.4395, 1.5745, 1.1495, 1.4406, 0.1815, 0.9602, 0.7205, 1.6087,\n",
       "                      1.4725, 0.9826, 1.2263])),\n",
       "             ('bn1.bias',\n",
       "              tensor([-3.5881e-01, -1.8501e-01,  4.0285e-01, -3.2647e-01,  6.5956e-01,\n",
       "                       1.2474e+00, -3.9717e-03,  6.6097e-01,  9.8886e-01,  1.2680e+00,\n",
       "                       1.4319e-02,  6.6507e-01, -8.6622e-01, -4.4260e-01,  4.0189e-03,\n",
       "                       6.8114e-02,  2.0296e-01,  9.3226e-01, -4.3035e-02,  8.3824e-02,\n",
       "                       5.3963e-01, -8.0672e-01, -9.6534e-01,  6.7577e-01, -7.9578e-02,\n",
       "                       1.1546e+00, -3.0081e-01,  3.8128e-01,  1.8214e-01,  5.1841e-01,\n",
       "                      -1.0025e-02,  9.0095e-01, -1.0808e+00, -3.5239e-01,  9.5603e-01,\n",
       "                       4.3506e-01,  3.0071e-01, -6.7611e-01, -3.3151e-01, -1.6101e+00,\n",
       "                       1.2687e+00, -3.1606e-01, -6.6191e-01,  7.2465e-01, -2.4094e-01,\n",
       "                      -9.5156e-02,  3.5746e-03,  7.4607e-01,  5.9509e-01, -5.6741e-01,\n",
       "                       1.0621e-01, -8.9432e-01,  2.3321e-02,  8.0780e-02,  4.7797e-01,\n",
       "                      -1.7674e-01, -2.8356e-02, -4.3802e-01, -7.4789e-01, -4.7050e-01,\n",
       "                      -8.2994e-01,  5.1044e-02, -4.7746e-01,  8.7021e-01, -7.5809e-01,\n",
       "                       1.6156e-01,  2.6918e-01, -1.0126e+00,  2.8360e-02, -3.4530e-01,\n",
       "                      -3.4783e-01,  2.5170e-01, -3.8310e-01, -4.3982e-01,  2.3893e-01,\n",
       "                      -9.7426e-01, -5.5961e-01, -6.8971e-01,  7.4028e-01,  1.8584e-01,\n",
       "                       3.3056e-01, -2.3300e-01,  1.2537e+00, -1.0998e-01,  2.6590e-01,\n",
       "                       4.9957e-01,  2.7041e-01,  5.5740e-01, -1.8942e+00,  1.6670e-03,\n",
       "                      -5.5373e-01,  1.0786e+00, -3.6530e-01, -8.2463e-02, -2.1981e-01,\n",
       "                       1.6353e-01,  1.7203e+00,  5.4240e-01, -4.2561e-01,  4.5973e-01,\n",
       "                      -1.1993e+00, -2.4784e-01, -3.4768e-02, -8.6348e-01, -1.3774e+00,\n",
       "                      -5.6779e-03, -4.4150e-04, -1.3460e+00, -1.3476e-01, -4.2730e-02,\n",
       "                       7.0334e-01,  9.3498e-01,  2.2657e-01, -1.4528e+00,  4.4792e-01,\n",
       "                      -5.0648e-01,  4.0496e-02, -3.8464e-02, -7.7673e-01, -4.3255e-01,\n",
       "                       1.1263e+00, -1.5996e-01,  4.0502e-03, -6.5081e-02,  2.6651e-01,\n",
       "                       5.0646e-02, -1.6607e-03,  1.6638e-02, -2.8642e-01,  3.5063e-01,\n",
       "                       1.6284e+00,  1.4449e-01,  2.1776e-01, -1.2512e+00,  1.4707e-01,\n",
       "                      -6.1008e-02,  4.8779e-01, -6.5549e-02,  8.0760e-01,  4.5079e-01,\n",
       "                       7.3242e-01, -8.1074e-01,  1.0409e+00,  3.2702e-01, -3.9341e-03,\n",
       "                      -6.9941e-02, -4.3451e-01, -4.3929e-01,  7.6375e-01,  1.2123e+00,\n",
       "                       5.1785e-02,  3.3000e-01, -3.8918e-02, -4.3913e-01,  3.3759e-02,\n",
       "                      -5.0435e-01, -1.1738e+00, -1.2027e-02,  5.7089e-02,  4.9307e-01,\n",
       "                      -3.0983e-01,  1.1790e+00,  9.2473e-01, -9.4050e-01, -4.2781e-01,\n",
       "                       1.3803e+00,  9.3513e-01,  1.4066e+00, -5.8887e-01, -8.7459e-02,\n",
       "                       1.3319e+00, -9.7947e-01, -8.5968e-01, -8.7603e-02,  3.2896e-01,\n",
       "                       2.9623e-02,  4.6514e-01,  1.0398e+00, -3.1744e-01, -2.6430e-01,\n",
       "                      -7.3333e-01,  5.1882e-03, -7.7151e-01,  9.8277e-01, -8.7241e-01,\n",
       "                      -1.0366e-02,  8.1416e-01,  3.6342e-01, -1.3090e+00, -1.0701e+00,\n",
       "                       6.7185e-01,  1.0831e+00])),\n",
       "             ('bn1.running_mean',\n",
       "              tensor([-4.6906e-01, -2.8066e-01,  4.6891e-01, -1.1247e+00,  7.5084e-01,\n",
       "                       2.5622e+00,  4.3741e-01, -3.1241e-01, -8.1244e-01,  3.4347e-01,\n",
       "                       1.4063e+00, -2.9693e+00, -2.8097e-01, -1.2506e+00,  0.0000e+00,\n",
       "                       2.1881e-01,  1.0621e+00,  4.9994e-01, -9.9984e-01, -3.7497e-01,\n",
       "                      -1.0317e+00, -4.0594e-01,  6.8750e-01,  2.1850e-01, -7.1913e-01,\n",
       "                       5.3200e-01, -1.8734e-01, -3.4431e-01,  8.7550e-01,  1.8128e+00,\n",
       "                      -3.1999e-02,  1.0938e+00,  1.5004e+00, -6.8725e-01,  2.5942e+00,\n",
       "                       6.5637e-01,  5.9409e-01,  3.1407e-02,  1.2810e+00, -1.5932e+00,\n",
       "                      -1.2806e+00,  2.8109e-01,  1.8775e-01,  1.1561e+00,  3.7466e-01,\n",
       "                      -9.9991e-01,  5.6231e-01,  1.1873e+00, -1.4062e+00, -3.7522e-01,\n",
       "                       9.4343e-02,  4.9962e-01, -6.5597e-01,  2.1891e-01, -1.0622e+00,\n",
       "                      -5.6216e-01,  1.7500e+00, -1.5638e-01, -8.7447e-01,  9.3697e-01,\n",
       "                      -1.4064e+00,  2.5044e-01, -3.1184e-01,  2.5100e-01,  9.4000e-02,\n",
       "                       6.8772e-01, -9.3937e-02, -1.6883e+00, -4.9978e-01,  7.1891e-01,\n",
       "                      -8.4375e-01,  4.0587e-01, -6.5619e-01, -1.8738e+00,  9.3593e-02,\n",
       "                       1.8703e-01,  8.4366e-01,  1.5588e-01, -5.0009e-01, -8.7461e-04,\n",
       "                      -3.4325e-01,  3.1250e-01,  8.1241e-01,  3.0625e-02,  5.9403e-01,\n",
       "                      -5.6206e-01,  6.8738e-01,  1.7814e+00, -1.6559e+00, -6.2478e-01,\n",
       "                       7.1853e-01,  1.9058e+00, -7.8169e-01,  5.3200e-01,  1.4064e+00,\n",
       "                      -1.2815e+00,  1.4067e+00, -1.2187e+00, -1.2185e+00, -2.8125e+00,\n",
       "                      -9.9972e-01, -1.1563e+00, -9.0606e-01,  1.5935e+00,  2.1841e-01,\n",
       "                       1.5606e-01,  0.0000e+00, -1.8856e-01, -2.8748e+00, -5.6300e-01,\n",
       "                       5.3125e-01,  9.4251e-02,  1.5650e-01, -2.5310e+00,  2.2188e+00,\n",
       "                      -1.2506e+00,  1.2528e-01, -9.9997e-01,  2.4061e+00, -9.6922e-01,\n",
       "                       3.4362e-01, -1.3127e+00,  0.0000e+00, -2.1247e+00,  1.3127e+00,\n",
       "                      -7.4972e-01,  0.0000e+00, -2.1567e+00,  9.6800e-01,  1.0623e+00,\n",
       "                       2.9058e+00, -9.0644e-01, -6.2125e-02,  6.2813e-02, -1.5622e-01,\n",
       "                       1.5311e+00, -1.7501e+00,  9.3781e-02, -9.0609e-01, -3.0970e-02,\n",
       "                      -8.4359e-01,  6.8766e-01, -8.1228e-01,  1.3124e+00, -9.6884e-01,\n",
       "                       9.6878e-01, -1.5647e-01, -1.2556e-01, -3.1281e-02,  3.1869e+00,\n",
       "                      -1.2487e-01, -3.1209e-01, -2.1856e-01, -2.4683e+00, -1.1254e+00,\n",
       "                       9.3937e-02,  6.5706e-01, -3.7584e-01, -1.7187e+00,  1.2501e+00,\n",
       "                       7.1906e-01,  1.5591e-01,  1.2500e+00, -1.5314e+00,  2.8156e-01,\n",
       "                       5.0066e-01, -1.8129e+00,  6.1907e-02, -7.1853e-01, -5.9388e-01,\n",
       "                      -2.4947e-01,  7.8150e-01, -1.6876e+00,  4.6866e-01, -1.2507e+00,\n",
       "                       4.9987e-01,  5.0003e-01,  3.1228e-01,  1.3123e+00, -9.0656e-01,\n",
       "                      -7.5022e-01, -9.6891e-01, -2.4997e-01,  1.7811e+00, -1.2503e-01,\n",
       "                       0.0000e+00,  1.2478e-01,  7.8125e-01,  4.3694e-01,  8.4341e-01,\n",
       "                       3.1437e-02,  1.5634e-01])),\n",
       "             ('bn1.running_var',\n",
       "              tensor([0.6448, 1.6924, 2.2564, 2.4993, 2.0664, 2.5768, 0.2540, 2.0931, 4.7381,\n",
       "                      1.5878, 1.2827, 4.6765, 2.0803, 2.5152, 0.0000, 2.3701, 4.7059, 1.8714,\n",
       "                      0.5805, 0.4999, 2.0952, 2.6377, 1.7703, 1.4665, 2.5954, 1.7413, 1.3829,\n",
       "                      3.0062, 0.8869, 2.8690, 2.7406, 2.9262, 4.2558, 1.6408, 4.1201, 1.3301,\n",
       "                      2.3141, 1.3865, 2.7257, 3.0229, 7.3049, 1.3698, 0.8677, 1.4906, 4.1758,\n",
       "                      1.4836, 1.9316, 1.3830, 1.9268, 0.2419, 1.8947, 5.8070, 2.3614, 1.4022,\n",
       "                      2.1892, 3.9953, 2.1931, 3.6190, 1.8552, 2.1249, 4.8929, 0.7100, 3.8335,\n",
       "                      6.0628, 2.3462, 0.9961, 1.8941, 3.5766, 3.2905, 2.9821, 1.6198, 1.2819,\n",
       "                      0.8135, 5.7914, 1.4443, 1.8999, 2.7803, 2.3293, 2.9688, 3.7411, 3.3944,\n",
       "                      2.4151, 1.1911, 2.4833, 4.5080, 3.6737, 4.0912, 3.1432, 2.6851, 0.2419,\n",
       "                      3.2415, 7.3790, 1.8542, 3.9982, 1.9906, 5.1128, 2.2500, 1.7245, 2.1758,\n",
       "                      5.0603, 1.9369, 0.7177, 2.0870, 4.0548, 1.5968, 0.5231, 0.0000, 5.2536,\n",
       "                      3.7899, 1.9956, 3.2889, 5.8935, 0.7822, 5.9341, 1.8544, 2.0002, 1.5321,\n",
       "                      0.7104, 1.7328, 2.0966, 1.2009, 2.4148, 0.0000, 3.0162, 3.3831, 3.2899,\n",
       "                      0.0000, 3.8145, 2.2893, 2.1245, 4.2170, 1.3131, 3.1561, 2.6410, 1.6844,\n",
       "                      4.3847, 4.5150, 1.7655, 3.1226, 1.3859, 1.1047, 2.2217, 4.6082, 1.8994,\n",
       "                      0.7406, 3.9652, 3.7478, 3.6613, 2.2255, 5.5106, 2.0475, 1.5774, 0.4349,\n",
       "                      1.2895, 1.1459, 1.3788, 2.6217, 2.9510, 2.8543, 3.2254, 1.1765, 3.9439,\n",
       "                      1.5488, 2.2572, 1.8868, 2.4550, 2.6748, 4.7049, 5.1107, 2.5086, 2.9685,\n",
       "                      1.3394, 2.9953, 1.0316, 2.0005, 0.2580, 2.9025, 2.6089, 1.3182, 2.6679,\n",
       "                      1.6766, 0.7411, 1.8065, 1.9195, 4.8233, 0.0000, 0.8236, 1.6605, 5.1572,\n",
       "                      2.1369, 2.1600, 4.6507])),\n",
       "             ('bn1.num_batches_tracked', tensor(37500)),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 3.1549e-01, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "                       -4.9149e-01,  0.0000e+00],\n",
       "                      [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "                       -0.0000e+00,  0.0000e+00],\n",
       "                      [ 0.0000e+00, -8.0704e-02,  2.0923e-01,  ...,  0.0000e+00,\n",
       "                        0.0000e+00,  4.8554e-02],\n",
       "                      ...,\n",
       "                      [ 0.0000e+00, -5.0000e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
       "                        5.7675e-01,  0.0000e+00],\n",
       "                      [ 4.0663e-01,  0.0000e+00,  4.7967e-01,  ..., -0.0000e+00,\n",
       "                        1.0310e-01, -0.0000e+00],\n",
       "                      [ 0.0000e+00,  0.0000e+00, -1.1159e-04,  ...,  3.5692e-03,\n",
       "                        7.3081e-04, -1.2926e-03]])),\n",
       "             ('bn2.weight',\n",
       "              tensor([0.6173, 1.0655, 0.3440, 1.3478, 0.7145, 0.4035, 1.1833, 0.7980, 1.6070,\n",
       "                      0.3019, 0.9113, 0.5472, 1.2178, 1.0994, 0.8246, 1.0517, 1.0380, 0.8573,\n",
       "                      0.6912, 1.1020, 0.4411, 1.7491, 0.1092, 0.8417, 1.2310, 1.4220, 0.1012,\n",
       "                      0.5415, 0.0571, 0.9172, 1.2292, 0.8794, 0.4239, 0.0755, 1.2860, 0.5236,\n",
       "                      1.3129, 0.4216, 1.2922, 0.7963, 1.3158, 0.4305, 1.3149, 0.9849, 0.4271,\n",
       "                      0.9509, 1.1578, 0.2406, 1.3480, 1.1077, 0.6919, 0.4087, 0.8354, 1.1298,\n",
       "                      1.3655, 0.4063, 0.8929, 1.2871, 1.2411, 0.6511, 0.5190, 1.2157, 0.9620,\n",
       "                      0.0187, 1.7742, 1.4622, 0.9158, 0.6444, 0.6866, 0.5904, 1.1237, 0.6735,\n",
       "                      1.2445, 1.5549, 1.5147, 1.6335, 1.8927, 0.8460, 1.0187, 0.6433, 1.3263,\n",
       "                      1.5981, 1.6808, 1.4969, 0.1536, 0.0992, 0.5925, 1.0949, 0.1209, 0.0786,\n",
       "                      1.0489, 1.5114, 1.3349, 1.1171, 1.3083, 0.7762, 0.0560, 0.4558, 1.6269,\n",
       "                      0.8511, 1.0023, 0.7985, 1.3756, 1.4574, 0.1993, 0.7936, 0.4096, 0.5056,\n",
       "                      1.4721, 1.0481, 1.4641, 1.5441, 0.9497, 0.5443, 1.2810, 1.2401, 0.4940,\n",
       "                      1.2854, 0.9103, 1.3026, 1.6011, 0.6481, 0.6482, 1.0709, 0.6167, 0.7614,\n",
       "                      0.1664, 0.1935, 0.9740, 1.2661, 1.2510, 1.2177, 1.7204, 0.9735, 1.5032,\n",
       "                      0.2677, 1.1279, 0.6503, 0.5741, 1.4460, 1.1108, 0.6328, 1.3039, 1.3530,\n",
       "                      1.4590, 1.0446, 1.0236, 1.3917, 1.4245, 0.9849, 1.3832, 0.6397, 0.9792,\n",
       "                      1.3711, 1.6615, 1.0201, 0.5468, 1.5071, 0.3684, 0.5774, 1.0781, 1.0799,\n",
       "                      0.8549, 1.2064, 0.8253, 0.7497, 0.2409, 1.4871, 0.6434, 1.5339, 0.9091,\n",
       "                      0.7610, 0.8179, 0.5148, 1.2538, 0.5355, 1.0177, 0.9839, 0.8160, 1.6013,\n",
       "                      0.2130, 0.0852, 1.6062, 0.1503, 0.6504, 1.3775, 0.2172, 1.0808, 0.0978,\n",
       "                      1.5894, 1.6454, 0.1723])),\n",
       "             ('bn2.bias',\n",
       "              tensor([-2.4984e-01,  2.3140e-01, -2.0013e-02,  4.7670e-01, -3.4638e-01,\n",
       "                       5.7729e-03, -2.5306e-01, -2.0826e-02,  1.2454e+00, -7.7507e-03,\n",
       "                      -2.4624e-01, -3.3997e-02,  4.6545e-01, -2.2630e-02, -5.4660e-02,\n",
       "                       2.9568e-01, -4.6772e-01, -1.9323e-01, -1.7847e-01,  8.2366e-01,\n",
       "                       1.4871e-01,  6.0743e-01, -8.1976e-04, -2.6109e-01,  8.6606e-01,\n",
       "                       4.9595e-02, -1.7394e-03, -9.7520e-02,  2.3350e-05,  2.2993e-01,\n",
       "                      -2.2014e-01,  7.2887e-01, -5.6291e-03, -2.0353e-03, -5.4682e-01,\n",
       "                       4.6038e-02, -9.5623e-01, -1.6513e-02, -4.2569e-01, -6.3756e-01,\n",
       "                       1.0443e-02,  4.3325e-03,  2.8483e-01, -5.9983e-01,  4.1716e-02,\n",
       "                      -1.1556e+00, -3.9856e-01,  3.0638e-03,  1.2513e+00,  2.1225e-01,\n",
       "                      -4.9115e-02,  1.3783e-02,  1.7540e-01,  6.2230e-02,  1.1418e+00,\n",
       "                       5.4787e-02, -6.5081e-01, -1.3554e-01,  8.8510e-01, -3.9217e-01,\n",
       "                      -7.5164e-02, -1.4924e-01,  2.2342e-01, -3.8381e-03, -8.1875e-01,\n",
       "                      -5.2722e-01,  2.8198e-01, -2.0158e-01,  1.0417e-01,  1.1390e-01,\n",
       "                      -4.1009e-01,  1.4448e-01,  5.0482e-01, -5.6657e-01, -6.8953e-02,\n",
       "                       2.6479e-01,  1.3561e+00, -2.8506e-01,  1.5880e-01, -5.1878e-02,\n",
       "                       3.6326e-01,  1.0562e+00,  1.4234e+00,  1.4629e+00,  3.9795e-04,\n",
       "                      -1.7004e-03, -3.9321e-01, -6.6766e-01, -2.7048e-02, -1.8698e-02,\n",
       "                       7.9412e-02, -6.1942e-01, -1.1408e+00,  8.9416e-02,  7.3198e-01,\n",
       "                      -2.4944e-01, -8.9953e-04,  1.9769e-02,  1.0214e+00,  2.8367e-02,\n",
       "                      -1.3699e-01,  9.6491e-02, -1.0275e+00,  2.2585e-01, -9.3087e-03,\n",
       "                      -6.6861e-02,  4.5452e-02, -1.4131e-02,  9.9318e-02, -2.4954e-01,\n",
       "                      -4.8615e-01, -8.7335e-01,  2.0454e-01,  4.3102e-02, -5.8951e-01,\n",
       "                       3.1197e-01, -5.6073e-03, -7.2943e-01,  8.8253e-03, -3.1003e-01,\n",
       "                       1.4366e+00,  3.0131e-01, -3.6863e-02,  5.8642e-01, -1.6911e-01,\n",
       "                       1.2485e-02,  8.9304e-05,  4.5848e-03,  1.4664e-01, -6.0226e-02,\n",
       "                      -3.5773e-01, -2.1236e-01,  3.7898e-01,  7.8496e-01, -1.2618e+00,\n",
       "                      -2.8429e-03, -2.9525e-01,  7.0653e-01, -9.3913e-03,  1.0225e+00,\n",
       "                       1.0581e+00, -2.4920e-01,  7.0249e-01, -1.0551e+00, -5.8538e-02,\n",
       "                      -6.9608e-02,  9.0887e-01, -8.4944e-01, -7.2464e-01,  5.1167e-01,\n",
       "                      -4.2474e-01,  1.1804e-01, -5.8163e-02,  4.4449e-01,  7.7382e-01,\n",
       "                      -7.6167e-01,  1.2435e-01, -6.4907e-01,  5.4104e-03,  1.6515e-01,\n",
       "                       4.1797e-01, -5.7006e-01, -2.7400e-01,  1.2117e+00, -6.1064e-01,\n",
       "                       4.5160e-01,  5.0781e-03,  1.1558e+00, -1.8501e-02,  9.1653e-01,\n",
       "                       3.8013e-01,  4.7818e-03, -2.3985e-01, -1.1544e-01,  7.8535e-01,\n",
       "                      -7.7911e-02,  7.1683e-01, -1.2103e-01,  6.3782e-01, -1.2733e+00,\n",
       "                       5.3461e-02, -1.5719e-02,  3.6224e-01,  2.4638e-04,  4.5603e-03,\n",
       "                      -1.0683e+00,  3.1870e-02,  1.8404e-01, -9.8438e-04, -1.2450e+00,\n",
       "                       1.1009e+00, -3.9023e-04])),\n",
       "             ('bn2.running_mean',\n",
       "              tensor([ 1.2497e+00, -4.9994e-01,  0.0000e+00, -1.5572e-01,  5.3144e-01,\n",
       "                       0.0000e+00, -3.1259e-01, -1.0936e+00,  3.4688e+00, -8.1263e-01,\n",
       "                       1.8703e-01, -2.1875e-01, -2.2807e+00, -8.4344e-01,  6.8731e-01,\n",
       "                      -3.7469e-01, -5.9275e-01, -1.4376e+00,  2.8113e-01,  2.1870e+00,\n",
       "                      -1.2519e-01,  4.3778e-01,  0.0000e+00,  6.5553e-01,  1.9059e+00,\n",
       "                       1.0928e+00,  0.0000e+00, -2.1875e-01,  0.0000e+00, -2.0314e+00,\n",
       "                      -1.3748e+00,  5.0025e-01, -4.6900e-01,  0.0000e+00, -5.6294e-01,\n",
       "                       1.1252e+00, -1.7808e+00,  4.0637e-01, -8.7522e-01,  1.3117e+00,\n",
       "                       7.8087e-01, -2.8106e-01, -1.7502e+00,  4.3716e-01, -1.8734e-01,\n",
       "                       3.4387e-01, -1.2534e-01,  0.0000e+00,  1.0325e+00,  3.7591e-01,\n",
       "                      -9.6900e-01,  0.0000e+00, -1.0629e+00,  7.1856e-01,  4.3703e-04,\n",
       "                       7.8137e-01, -1.3439e+00,  2.1856e-01,  1.4691e+00, -6.5666e-01,\n",
       "                       3.1469e-02,  1.4056e+00, -2.5025e-01,  0.0000e+00,  5.3022e-01,\n",
       "                      -2.9686e+00, -1.9368e+00, -6.2563e-02,  3.1209e-01, -7.8091e-01,\n",
       "                       1.0303e+00, -3.7512e-01, -1.3128e+00, -2.0937e+00,  3.7476e-04,\n",
       "                      -2.0321e+00,  1.0316e+00,  3.7444e-01, -3.1188e-01, -4.3766e-01,\n",
       "                       2.1878e-04, -8.4359e-01,  3.1216e-01, -9.0563e-01,  0.0000e+00,\n",
       "                       0.0000e+00,  6.5625e-01,  6.2569e-01,  0.0000e+00,  0.0000e+00,\n",
       "                       1.1875e+00,  8.4294e-01,  1.0003e+00, -1.3436e+00,  6.2541e-01,\n",
       "                       2.4981e-01,  0.0000e+00, -2.4994e-01,  9.3769e-01, -5.6253e-01,\n",
       "                       1.5933e+00,  3.0305e+00, -1.6559e+00,  6.5556e-01,  0.0000e+00,\n",
       "                       1.5609e-01,  6.2469e-02,  9.6866e-01,  4.0606e-01, -1.7189e+00,\n",
       "                      -6.5678e-01,  2.0620e+00, -2.3755e+00, -3.4362e-01,  6.2407e-02,\n",
       "                       1.0945e+00,  3.4378e-01, -1.0318e+00, -1.9059e+00,  2.1867e+00,\n",
       "                       9.3688e-02,  1.0626e+00, -6.2562e-02, -6.2656e-02, -9.6859e-01,\n",
       "                      -4.3725e-01,  0.0000e+00,  0.0000e+00,  1.6875e+00, -3.4434e-01,\n",
       "                      -1.0623e+00,  1.9054e+00,  5.9275e-01, -1.8741e-01, -1.0946e+00,\n",
       "                       2.1862e-01,  3.2189e+00, -7.1863e-01, -3.4381e-01,  4.0597e-01,\n",
       "                       1.4068e+00,  2.4978e-01,  6.3000e-02,  3.1291e-01,  2.0942e+00,\n",
       "                      -7.1738e-01,  7.8056e-01, -1.3432e+00,  4.3694e-01, -1.2190e+00,\n",
       "                      -9.6956e-01,  1.6564e+00,  7.4997e-01,  1.4689e+00, -5.3194e-01,\n",
       "                      -3.1159e-01,  4.3759e-01, -1.8700e-01, -1.0935e+00,  6.2481e-01,\n",
       "                       1.7189e+00, -1.6246e+00,  5.3144e-01, -3.4328e-01,  1.4997e+00,\n",
       "                       4.3747e-01,  0.0000e+00,  3.4328e-01, -5.9387e-01, -4.9947e-01,\n",
       "                      -1.4686e+00,  9.9975e-01,  5.6234e-01, -1.2463e-01,  1.0003e+00,\n",
       "                      -3.1437e-02, -2.9373e+00,  4.0575e-01, -1.4063e+00, -1.4069e+00,\n",
       "                       0.0000e+00,  0.0000e+00, -7.5022e-01,  0.0000e+00, -5.6231e-01,\n",
       "                       1.2459e-01,  0.0000e+00, -5.9372e-01,  0.0000e+00,  4.1564e+00,\n",
       "                       5.6175e-01,  0.0000e+00])),\n",
       "             ('bn2.running_var',\n",
       "              tensor([ 2.0644,  5.1590,  0.0000, 16.5219,  3.0310,  0.0000,  8.2889,  1.8941,\n",
       "                      27.4680,  1.0602,  6.7358,  0.6278,  6.4019,  6.5888,  2.6081,  7.4040,\n",
       "                       5.0903,  6.1902,  0.6604,  6.4149,  0.7582, 17.3499,  0.0000,  6.6854,\n",
       "                       5.8986, 16.0784,  0.0000,  0.5636,  0.0000,  3.3848, 26.0339,  2.3226,\n",
       "                       0.5795,  0.0000, 12.0600,  1.1453, 15.3440,  1.0876,  8.4346,  4.0927,\n",
       "                      12.5019,  0.7248,  5.0986,  3.2227,  0.4800,  3.8456,  3.5960,  0.0000,\n",
       "                      10.9342,  8.6287,  2.7397,  0.0000,  3.4822,  7.6924,  7.4221,  0.7571,\n",
       "                       8.4226,  5.9203, 15.4168,  1.9742,  0.8696, 13.3474,  1.2902,  0.0000,\n",
       "                      16.4491, 24.0858,  8.2522,  3.2860,  5.1236,  1.3377, 13.6409,  0.9522,\n",
       "                      24.9910,  7.9608, 16.1974,  8.3580, 19.7082,  4.1778,  3.9003,  2.1248,\n",
       "                       9.8722, 11.1045, 12.4182,  9.7649,  0.0000,  0.0000,  0.8133,  7.2083,\n",
       "                       0.0000,  0.0000,  8.8046, 25.6206,  3.6803,  7.9735, 11.9170,  1.8712,\n",
       "                       0.0000,  0.7743, 15.3553,  1.6736,  6.1202,  4.9346,  8.2986, 11.5898,\n",
       "                       0.0000,  2.9110,  0.5767,  0.8703, 11.6024,  6.3365, 10.6895, 18.3207,\n",
       "                       5.5296,  0.9430,  8.3185, 20.5247,  0.6845,  7.0632,  3.8961, 14.7348,\n",
       "                      10.0216,  2.8354,  1.7377,  3.9327,  2.4842,  2.1901,  0.0000,  0.0000,\n",
       "                       4.2864, 10.8141,  8.6391,  8.0188, 25.8585,  4.0931, 16.5379,  0.8214,\n",
       "                      10.6313,  1.7563,  0.3622, 25.9780,  7.2211,  1.6136,  6.4498, 10.2916,\n",
       "                      17.0577, 12.1415,  5.4023,  7.3963, 17.9900,  7.2055,  9.3833,  4.1736,\n",
       "                       7.1620, 15.9943, 17.4242,  5.7032,  4.2540, 30.1484,  1.3135,  1.2742,\n",
       "                       7.6947,  9.0225,  9.6748, 11.0713,  4.6445,  2.3826,  0.0000,  8.8827,\n",
       "                       2.4424, 21.0287,  5.0308,  4.2595,  4.3831,  3.0154,  7.7410,  1.4507,\n",
       "                       7.0933,  5.4128,  2.3140, 17.8537,  0.0000,  0.0000, 13.8747,  0.0000,\n",
       "                       3.0292, 12.0499,  0.0000,  7.8593,  0.0000, 21.1018, 29.8545,  0.0000])),\n",
       "             ('bn2.num_batches_tracked', tensor(37500)),\n",
       "             ('fc3.weight',\n",
       "              tensor([[ 0.0000e+00,  5.2239e-01, -0.0000e+00,  ..., -2.3643e-01,\n",
       "                        6.1171e-01,  9.9262e-03],\n",
       "                      [-2.3785e-01, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "                       -0.0000e+00,  4.4405e-02],\n",
       "                      [ 3.9186e-03,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "                       -0.0000e+00,  0.0000e+00],\n",
       "                      ...,\n",
       "                      [-0.0000e+00, -8.1292e-02, -7.7567e-02,  ...,  3.9855e-01,\n",
       "                        0.0000e+00, -4.7530e-03],\n",
       "                      [-7.0687e-06,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "                        0.0000e+00,  3.9536e-07],\n",
       "                      [-5.9270e-06, -1.7025e-06,  1.1299e-06,  ...,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00]])),\n",
       "             ('bn3.weight',\n",
       "              tensor([ 9.2523e-01,  9.7434e-01,  1.8814e-01,  2.2925e-02,  2.1301e-02,\n",
       "                       3.8732e-01,  1.6786e+00,  1.1329e-02,  1.6623e-01,  1.2945e+00,\n",
       "                       3.7678e-01,  1.5040e-01,  2.2154e-01,  1.3012e-01,  2.7429e-41,\n",
       "                       2.7429e-41,  1.4729e+00,  1.3544e-01,  1.4408e-01,  7.7828e-02,\n",
       "                      -2.9674e-02,  4.5653e-01,  1.7318e-01,  9.7636e-02,  8.0741e-02,\n",
       "                       2.2267e-02,  9.5820e-02,  6.4795e-02, -7.3053e-02,  2.4527e-02,\n",
       "                       3.8344e-01,  4.6404e-01,  8.0373e-01,  3.9770e-02,  2.3924e-01,\n",
       "                       1.2292e+00, -2.1415e-02,  6.5928e-02,  1.0236e-01,  3.8690e-01,\n",
       "                       1.1260e-01,  2.9399e-01,  1.1002e-01,  1.4991e-01,  4.9164e-01,\n",
       "                       6.2902e-02, -2.7985e-02,  3.2554e-01,  1.2453e+00,  6.4654e-02,\n",
       "                       1.4596e+00,  5.5737e-01,  2.9278e-01,  7.4572e-02, -3.3164e-02,\n",
       "                       2.9028e-03,  6.1606e-02,  5.1039e-02,  9.4473e-02,  9.4235e-02,\n",
       "                       1.1201e+00,  9.2355e-02,  2.7429e-41,  2.4239e-01,  9.5804e-02,\n",
       "                       1.3906e-01,  1.5348e-01,  1.7316e-01,  1.0354e+00,  1.0233e+00,\n",
       "                       8.8016e-02,  1.0926e-01,  2.6728e-02,  3.1999e-01,  4.8395e-01,\n",
       "                       1.1914e+00,  3.6620e-02,  4.6454e-02,  2.8663e-02,  6.3020e-02,\n",
       "                       4.4969e-02,  7.1148e-02,  1.3357e+00,  5.3717e-02,  6.8446e-02,\n",
       "                       6.6016e-02,  2.5530e-01,  6.3616e-02,  1.1839e-01,  2.5161e-02,\n",
       "                       2.1255e-02,  7.0114e-02,  7.1216e-02,  3.1784e-02,  3.8196e-01,\n",
       "                       6.0461e-01,  5.7239e-02,  8.1942e-02,  1.4153e-01,  8.3755e-02,\n",
       "                       1.0861e+00,  8.2719e-01,  4.2764e-01,  1.0872e+00,  4.7380e-01,\n",
       "                       1.2029e-01,  7.8938e-02,  1.2586e-01,  7.6795e-01,  5.9284e-02,\n",
       "                       5.7485e-02,  8.7794e-02,  3.5210e-01,  6.3250e-02,  5.6216e-02,\n",
       "                       9.9535e-02,  1.1206e+00,  5.5472e-01,  4.8203e-02,  5.7181e-02,\n",
       "                       4.8029e-01,  8.6995e-01,  1.3905e-01,  9.4818e-01,  6.1962e-02,\n",
       "                       6.8251e-02,  6.6814e-02,  2.3767e-02,  8.4977e-01,  7.0213e-02,\n",
       "                       1.5861e-02,  5.2352e-01,  5.1903e-02,  7.0223e-02,  8.6539e-02,\n",
       "                       1.3528e-01,  4.7683e-02,  2.7429e-41,  2.7429e-41,  5.4085e-01,\n",
       "                       4.8059e-01,  2.1095e-02,  9.1250e-02,  9.5915e-02, -9.1564e-03,\n",
       "                       5.6337e-01,  6.6574e-01,  5.5638e-01,  9.7704e-01,  7.5100e-01,\n",
       "                       6.9288e-02,  6.2545e-01,  6.2283e-02, -7.6246e-03,  2.7491e-01,\n",
       "                       9.3395e-02,  1.0017e-01,  3.3148e-01,  8.2855e-01,  4.3303e-02,\n",
       "                       2.7429e-41,  7.3782e-02,  1.2429e-01,  2.7429e-41,  1.0210e-01,\n",
       "                      -5.4953e-03,  2.7429e-41,  6.2517e-01,  8.1255e-01,  1.4681e-01,\n",
       "                       3.3615e-01,  8.4766e-02,  9.5894e-03,  1.4145e-01,  7.4338e-02,\n",
       "                       1.6306e-01,  2.0979e-01,  5.1327e-02,  8.5104e-02,  1.3132e+00,\n",
       "                       3.6921e-02,  2.6402e-01,  6.2804e-01,  3.0938e-02,  9.2247e-02,\n",
       "                       9.2901e-02,  1.1017e-01,  1.3285e-01,  1.4179e+00,  9.3930e-01,\n",
       "                       1.0089e-01,  7.4419e-03])),\n",
       "             ('bn3.bias',\n",
       "              tensor([-6.6320e-01, -4.0210e-01, -1.6859e-02, -2.8986e-02,  2.9786e-02,\n",
       "                      -7.2411e-02, -1.1494e+00,  7.2288e-02, -6.9233e-03, -4.8629e-01,\n",
       "                       2.8672e-01,  4.8004e-02,  1.2607e-01, -1.9811e-02,  0.0000e+00,\n",
       "                       0.0000e+00, -5.7369e-01, -6.1191e-02, -1.3017e-02, -7.1297e-02,\n",
       "                       2.5546e-01,  2.9265e-01,  1.2227e-01,  8.3830e-02, -8.2564e-02,\n",
       "                      -1.4341e-01, -7.6224e-02,  2.4522e-02,  2.8117e-02,  6.8389e-02,\n",
       "                      -7.8235e-02,  1.9489e-01,  1.6978e-01,  2.3783e-01,  7.8887e-02,\n",
       "                      -4.3741e-01,  6.5808e-02, -4.7527e-02, -4.6457e-02, -1.4490e-01,\n",
       "                      -1.0675e-02,  1.5949e-01, -1.8679e-02, -2.0031e-02, -1.1502e-01,\n",
       "                       2.4749e-03, -2.2488e-02,  1.3555e-01, -3.7731e-01, -1.3455e-02,\n",
       "                       8.6659e-01,  2.4232e-01, -5.8190e-03, -1.2680e-02,  1.3032e-01,\n",
       "                       2.5459e-01,  2.0342e-02,  5.1609e-02, -4.9454e-02, -1.2568e-01,\n",
       "                      -1.6424e-01, -8.6133e-03,  0.0000e+00,  1.1227e-01, -4.0457e-02,\n",
       "                      -1.0017e-02, -4.0770e-02, -2.8616e-03,  9.3054e-03, -5.5214e-01,\n",
       "                       1.5997e-02, -3.2244e-02,  2.7638e-02, -8.0808e-02,  2.7575e-01,\n",
       "                      -8.7356e-02, -3.1870e-02, -9.9088e-02,  1.1551e-01,  1.5657e-01,\n",
       "                      -7.3982e-02,  1.6823e-01, -6.5871e-01,  1.5412e-01, -4.8158e-02,\n",
       "                       2.6802e-02, -1.0068e-01, -5.2610e-03, -1.7597e-01,  5.8772e-02,\n",
       "                       3.2138e-02, -1.3024e-02,  9.2065e-02, -7.3883e-02,  1.4999e-01,\n",
       "                       1.0231e-01, -9.3411e-02,  1.0975e-01,  1.6913e-01, -4.0951e-02,\n",
       "                       3.7506e-01, -1.9552e-01,  2.9376e-01, -5.4471e-01, -2.6776e-01,\n",
       "                       2.3520e-02, -2.0884e-02, -8.8000e-02, -4.3261e-01, -2.5507e-02,\n",
       "                      -3.5400e-02, -5.2906e-02, -1.9597e-01, -2.9161e-02, -1.4128e-01,\n",
       "                       3.4501e-02,  2.7374e-02,  3.4706e-01, -5.7157e-02,  2.8829e-02,\n",
       "                      -2.4072e-01, -1.7761e-01, -1.0068e-01,  5.9152e-01, -7.5224e-02,\n",
       "                      -3.0949e-03, -6.3863e-02,  5.4910e-03,  4.7909e-01, -9.6542e-03,\n",
       "                       2.3389e-02,  5.0276e-01, -8.0682e-02,  1.1810e-02,  7.1334e-05,\n",
       "                      -2.2287e-01, -3.9674e-02,  0.0000e+00,  0.0000e+00, -3.2098e-01,\n",
       "                       1.6541e-01,  1.2178e-01,  6.1508e-02,  3.4798e-02, -1.8887e-01,\n",
       "                       4.3595e-01, -4.7077e-01,  3.4033e-01,  3.0663e-01, -3.7863e-01,\n",
       "                      -4.5321e-02,  3.3925e-01, -4.4665e-02,  1.4144e-03, -1.8565e-02,\n",
       "                      -1.2456e-01,  8.7672e-02,  9.1048e-02, -2.5634e-01, -9.6804e-02,\n",
       "                       0.0000e+00,  3.6324e-02,  1.6887e-01,  0.0000e+00, -1.8550e-03,\n",
       "                       4.3518e-02,  0.0000e+00, -3.6112e-01, -2.9881e-01,  7.4638e-02,\n",
       "                       9.9938e-02,  5.8203e-02,  1.1725e-01,  2.6359e-03, -7.1301e-02,\n",
       "                       2.9140e-02, -5.0359e-02,  1.5281e-01,  3.9444e-02, -7.5536e-01,\n",
       "                      -1.0317e-02,  8.9798e-02, -2.6706e-01,  3.1014e-02,  2.3063e-03,\n",
       "                       6.8882e-02,  3.9780e-02, -2.6330e-02, -8.6393e-01,  8.0832e-01,\n",
       "                       2.3409e-02, -1.5290e-01])),\n",
       "             ('bn3.running_mean',\n",
       "              tensor([ 0.8124, -3.1247,  0.0000,  0.0000,  0.0000,  0.2811,  1.6561,  0.0000,\n",
       "                       0.0000,  3.4377,  0.2499,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "                      -0.7808,  0.0000,  0.0000,  0.0000,  0.0000, -0.5939,  0.0000,  0.0000,\n",
       "                       0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.6250, -0.4374,\n",
       "                       3.0940,  0.0000,  0.0000, -0.2495,  0.0000,  0.0000,  0.0000,  0.2189,\n",
       "                       0.0000,  0.0000,  0.0000,  0.0000,  0.6562,  0.0000,  0.0000,  0.4372,\n",
       "                      -1.0623,  0.0000,  0.0936, -1.5940, -1.5626,  0.0000,  0.0000,  0.0000,\n",
       "                       0.0000,  0.0000,  0.0000,  0.0000, -1.5941,  0.0000,  0.0000,  0.0000,\n",
       "                       0.0000,  0.0000,  0.0000,  0.0000,  0.3440, -0.8127,  0.0000,  0.0000,\n",
       "                       0.0000,  0.4373, -0.4994, -4.0631,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "                       0.0000,  0.0000, -3.7186,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "                       0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0626,  0.7805,\n",
       "                       0.0000,  0.0000,  0.0000,  0.0000,  2.0942, -3.5621, -1.1873, -1.3438,\n",
       "                      -0.9685,  0.0000,  0.0000,  0.0000, -0.0935,  0.0000,  0.0000,  0.0000,\n",
       "                      -0.3750,  0.0000,  0.0000,  0.0000,  0.2508, -0.7191,  0.0000,  0.0000,\n",
       "                      -1.7498, -1.1258,  0.0000, -0.5304,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "                       2.7184,  0.0000,  0.0000, -0.4690,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "                       0.0000,  0.0000,  0.0000,  0.6251,  0.4376,  0.0000,  0.0000,  0.0000,\n",
       "                       0.0000,  0.1562, -1.3128,  0.5937, -1.1566, -2.4690,  0.0000,  1.5003,\n",
       "                       0.0000,  0.0000, -0.0627,  0.0000,  0.0000,  1.5623, -1.4370,  0.0000,\n",
       "                       0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.3125,\n",
       "                      -0.5628,  0.0000,  0.2185,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "                       0.0000,  0.0000,  0.0000, -1.1875,  0.0000,  0.0000, -1.0936,  0.0000,\n",
       "                       0.0000,  0.0000,  0.0000,  0.0000, -0.0932,  1.6873,  0.0000,  0.0000])),\n",
       "             ('bn3.running_var',\n",
       "              tensor([12.7951, 16.9510,  0.0000,  0.0000,  0.0000,  2.0152, 43.2538,  0.0000,\n",
       "                       0.0000, 40.1768,  1.9364,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "                      25.8537,  0.0000,  0.0000,  0.0000,  0.0000,  5.2149,  0.0000,  0.0000,\n",
       "                       0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  3.9195,  8.3794,\n",
       "                      20.6021,  0.0000,  0.0000, 27.4887,  0.0000,  0.0000,  0.0000,  1.4668,\n",
       "                       0.0000,  0.0000,  0.0000,  0.0000,  7.3995,  0.0000,  0.0000,  3.0284,\n",
       "                      32.7662,  0.0000, 16.6726, 20.0497,  3.4154,  0.0000,  0.0000,  0.0000,\n",
       "                       0.0000,  0.0000,  0.0000,  0.0000, 28.5046,  0.0000,  0.0000,  0.0000,\n",
       "                       0.0000,  0.0000,  0.0000,  0.0000, 35.4455, 22.5494,  0.0000,  0.0000,\n",
       "                       0.0000,  2.5121,  6.5159, 40.4511,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "                       0.0000,  0.0000, 40.7273,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "                       0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  3.3492, 21.7206,\n",
       "                       0.0000,  0.0000,  0.0000,  0.0000, 42.0981, 12.8385,  5.6442, 19.0048,\n",
       "                       6.4201,  0.0000,  0.0000,  0.0000,  9.1192,  0.0000,  0.0000,  0.0000,\n",
       "                       0.6935,  0.0000,  0.0000,  0.0000, 30.8934,  2.7902,  0.0000,  0.0000,\n",
       "                       8.5141, 19.2111,  0.0000, 16.3176,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "                       6.7891,  0.0000,  0.0000,  3.5462,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "                       0.0000,  0.0000,  0.0000,  4.5003,  7.8660,  0.0000,  0.0000,  0.0000,\n",
       "                       0.0000,  5.2977,  6.2875, 15.3432, 11.6863, 16.4546,  0.0000,  7.0311,\n",
       "                       0.0000,  0.0000,  2.5114,  0.0000,  0.0000,  1.4804,  7.3527,  0.0000,\n",
       "                       0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  3.9010,\n",
       "                      17.2991,  0.0000,  3.0145,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "                       0.0000,  0.0000,  0.0000, 24.0249,  0.0000,  0.0000,  5.7027,  0.0000,\n",
       "                       0.0000,  0.0000,  0.0000,  0.0000, 28.6621,  8.4824,  0.0000,  0.0000])),\n",
       "             ('bn3.num_batches_tracked', tensor(37500)),\n",
       "             ('fc4.weight',\n",
       "              tensor([[-0.0000, -0.0000, -0.0000,  ..., -0.5001,  0.0000, -0.0000],\n",
       "                      [ 0.0000, -0.0000, -0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
       "                      [-0.0000,  0.5332,  0.2526,  ...,  0.0000,  0.0000,  0.1404],\n",
       "                      ...,\n",
       "                      [ 0.0000, -0.0000, -0.2441,  ..., -0.0000,  0.0424,  0.0000],\n",
       "                      [ 0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
       "                      [-0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]))])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"state_dict.pt\", map_location=device)\n",
    "print(f\"keys = {checkpoint.keys()}\")\n",
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNISTQATModel(\n",
       "  (quant_inp): QuantIdentity(\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): Identity()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClamp()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "          )\n",
       "          (scaling_impl): ConstScaling(\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): Identity()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (value): StatelessBuffer()\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc1): QuantLinear(\n",
       "    in_features=784, out_features=192, bias=False\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "        )\n",
       "        (scaling_impl): ConstScaling(\n",
       "          (restrict_clamp_scaling): _RestrictClampValue(\n",
       "            (clamp_min_ste): Identity()\n",
       "            (restrict_value_impl): FloatRestrictValue()\n",
       "          )\n",
       "          (value): StatelessBuffer()\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (bn1): BatchNorm1d(192, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
       "  (q1): QuantIdentity(\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): Identity()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClamp()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "          )\n",
       "          (scaling_impl): ConstScaling(\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): Identity()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (value): StatelessBuffer()\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc2): QuantLinear(\n",
       "    in_features=192, out_features=192, bias=False\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "        )\n",
       "        (scaling_impl): ConstScaling(\n",
       "          (restrict_clamp_scaling): _RestrictClampValue(\n",
       "            (clamp_min_ste): Identity()\n",
       "            (restrict_value_impl): FloatRestrictValue()\n",
       "          )\n",
       "          (value): StatelessBuffer()\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (bn2): BatchNorm1d(192, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
       "  (q2): QuantIdentity(\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): Identity()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClamp()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "          )\n",
       "          (scaling_impl): ConstScaling(\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): Identity()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (value): StatelessBuffer()\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc3): QuantLinear(\n",
       "    in_features=192, out_features=192, bias=False\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "        )\n",
       "        (scaling_impl): ConstScaling(\n",
       "          (restrict_clamp_scaling): _RestrictClampValue(\n",
       "            (clamp_min_ste): Identity()\n",
       "            (restrict_value_impl): FloatRestrictValue()\n",
       "          )\n",
       "          (value): StatelessBuffer()\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (bn3): BatchNorm1d(192, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
       "  (q3): QuantIdentity(\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): Identity()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClamp()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "          )\n",
       "          (scaling_impl): ConstScaling(\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): Identity()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (value): StatelessBuffer()\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc4): QuantLinear(\n",
       "    in_features=192, out_features=10, bias=False\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "        )\n",
       "        (scaling_impl): ConstScaling(\n",
       "          (restrict_clamp_scaling): _RestrictClampValue(\n",
       "            (clamp_min_ste): Identity()\n",
       "            (restrict_value_impl): FloatRestrictValue()\n",
       "          )\n",
       "          (value): StatelessBuffer()\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18,\n",
       "        -17, -16, -15, -14, -13, -12, -11, -10,  -9,  -8,  -7,  -6,  -5,  -4,\n",
       "         -3,  -2,  -1,   0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
       "         11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,\n",
       "         25,  26,  27,  28,  29,  30,  31], dtype=torch.int8)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.int_weight().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the numpy test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 313/313 [00:01<00:00, 197.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# Prepare tests\n",
    "test_data = np.zeros((len(test_loader.dataset), img_size * img_size))\n",
    "test_target = np.zeros((len(test_loader.dataset), 1))\n",
    "idx = 0\n",
    "\n",
    "for data, target in tqdm(test_loader):\n",
    "    target_np = target.cpu().numpy()\n",
    "    for idx_batch, im in enumerate(data.numpy()):\n",
    "        test_data[idx] = im\n",
    "        test_target[idx] = target_np[idx_batch]\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data.shape = (10000, 784)\n",
      "type(test_data) = <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"{test_data.shape = }\")\n",
    "print(f\"{type(test_data) = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference in FHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = {}\n",
    "current_index = 3\n",
    "test_data_length_reduced = 2  # This is notably the length of the computation in FHE\n",
    "test_data_length_full = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Any\n",
    "def convert_torch_tensor_or_numpy_array_to_numpy_array(\n",
    "    torch_tensor_or_numpy_array: Union[torch.Tensor, np.ndarray],\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Convert a torch tensor or a numpy array to a numpy array.\n",
    "    source: src/concrete/ml/torch/compile.py\n",
    "    \n",
    "    Args:\n",
    "        torch_tensor_or_numpy_array (Tensor): the value that is either\n",
    "            a torch tensor or a numpy array.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: the value converted to a numpy array.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        torch_tensor_or_numpy_array\n",
    "        if isinstance(torch_tensor_or_numpy_array, np.ndarray)\n",
    "        else torch_tensor_or_numpy_array.cpu().numpy()\n",
    "    )\n",
    "\n",
    "def to_tuple(x: Any) -> tuple:\n",
    "    \"\"\"Make the input a tuple if it is not already the case.\n",
    "\n",
    "    Args:\n",
    "        x (Any): The input to consider. It can already be an input.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The input as a tuple.\n",
    "    \"\"\"\n",
    "    # If the input is not a tuple, return a tuple of a single element\n",
    "    if not isinstance(x, tuple):\n",
    "        return (x,)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputset_as_numpy_tuple = tuple(\n",
    "    convert_torch_tensor_or_numpy_array_to_numpy_array(val) for val in to_tuple(test_data)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.42421296, -0.42421296, -0.42421296, ..., -0.42421296,\n",
       "         -0.42421296, -0.42421296],\n",
       "        [-0.42421296, -0.42421296, -0.42421296, ..., -0.42421296,\n",
       "         -0.42421296, -0.42421296],\n",
       "        [-0.42421296, -0.42421296, -0.42421296, ..., -0.42421296,\n",
       "         -0.42421296, -0.42421296],\n",
       "        ...,\n",
       "        [-0.42421296, -0.42421296, -0.42421296, ..., -0.42421296,\n",
       "         -0.42421296, -0.42421296],\n",
       "        [-0.42421296, -0.42421296, -0.42421296, ..., -0.42421296,\n",
       "         -0.42421296, -0.42421296],\n",
       "        [-0.42421296, -0.42421296, -0.42421296, ..., -0.42421296,\n",
       "         -0.42421296, -0.42421296]]),)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputset_as_numpy_tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process where data is processed in `compile_and_test`\n",
    "\n",
    "```\n",
    "compile_and_test -> compile_brevitas_qat_model -> compile_onnx_model -> _compile_torch_or_onnx_model -> build_quantized_module -> \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "concrete-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
